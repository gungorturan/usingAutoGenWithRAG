# -*- coding: utf-8 -*-
"""mathToPython.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sHD1As8UN-5W7FS26EPgHMBvPF7pLvUh

# Install and Run Ollama
"""

# !curl -fsSL https://ollama.com/install.sh | sh

import subprocess
subprocess.Popen(["ollama", "serve"])

"""# Pull LLama3"""

# !ollama pull llama3

"""# Installing AutoGen"""

# !pip install pyautogen[retrievechat]

"""# Conversation between RAUP and RAA"""

import autogen
from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent
from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent

llm_config = {"model": "llama3", "api_key":"ollama", "base_url": "http://localhost:11434/v1"}

def termination_msg(x):
    return isinstance(x, dict) and "TERMINATE" == str(x.get("content", ""))[-9:].upper()

boss = autogen.UserProxyAgent(
    name="Boss",
    is_termination_msg = termination_msg,
    human_input_mode = "NEVER",
    code_execution_config = False,
    default_auto_reply = "Reply 'TERMINATE' if the task is done",
    description = "The boss who ask questions and give tasks."
)

boss_aid = RetrieveUserProxyAgent(
    name = "Boss_Assistant",
    is_termination_msg = termination_msg,
    human_input_mode = "NEVER",
    code_execution_config = False,
    default_auto_reply = "Reply 'TERMINATE' if the task is done",
    max_consecutive_auto_reply=3,
    retrieve_config = {
        "task": "code",
        "docs_path": "mathh.pdf",
        "model": llm_config["model"],
        "vector_db": "chroma",
        "collection_name": "groupchat",
        "get_or_create": True,
    },
    description = "Assistant who has extra content retrieval power for solving difficult problems.",
)

math = autogen.AssistantAgent(
    name="Mathematician",
    is_termination_msg = termination_msg,
    system_message = "You are a mathematician, you simplify math problems to make them suitable for programming. Reply `TERMINATE` in the end when everything is done.",
    llm_config = llm_config,
    description = "Mathematician who can recognize mathematical problems, solve them and simplify them."
)

coder = autogen.AssistantAgent(
    name="Senior_Python_Engineer",
    is_termination_msg=termination_msg,
    system_message="You are a senior python engineer, you provide python code to answer questions. Reply `TERMINATE` in the end when everything is done.",
    llm_config=llm_config,
    description="Senior Python Engineer who can write code to solve problems and answer questions.",
)

pm = autogen.AssistantAgent(
    name="Product_Manager",
    is_termination_msg=termination_msg,
    system_message="You are a product manager. Your only job is to make a road map for mathematician and senior_python_engineer to follow the question asked. Reply `TERMINATE` in the end when everything is done.",
    llm_config=llm_config,
    description="Product Manager who can design and plan the project.",
)

reviewer = autogen.AssistantAgent(
    name="Code_Reviewer",
    is_termination_msg=termination_msg,
    system_message="You are a code reviewer. Reply `TERMINATE` in the end when everything is done.",
    llm_config=llm_config,
    description="Code Reviewer who can review the code.",
)

problem = "Solve the first question."

def _reset_agents():
    boss.reset()
    boss_aid.reset()
    math.reset()
    coder.reset()
    pm.reset()
    reviewer.reset()

_reset_agents()
groupchat = autogen.GroupChat(
    agents=[boss_aid, pm, math, coder, reviewer], messages=[], max_round=12, speaker_selection_method="round_robin"
)
manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)

boss_aid.initiate_chat(
    manager,
    message=boss_aid.message_generator,
    problem=problem,
    n_results=3,
)